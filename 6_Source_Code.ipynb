{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP CsQA Ensemble Code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "_gFMMEA0k1OY",
        "4nmlIW0FX7Wc",
        "NZg5oAvapesg",
        "zpllytgUx4o1",
        "XtatYb9aYBR8",
        "_RrDP1HEhOOw",
        "BZW8jkTAlfW0",
        "umAq5aHuYwKw",
        "tc4Zvt0sYyNu",
        "oR6OwjPa2cgx",
        "WKSx5GC1kzT0",
        "3Ilhn0hLi-rf",
        "-770Ck8KY_kC",
        "HengkzJGFmFf",
        "khyd4eGclF8e",
        "IN22E6xo10eR",
        "HP1fl7KjXNsU",
        "tHy3N4b3ZRo0",
        "Xe1inMNVX-Uu",
        "vld1M6mqfifY",
        "GDJRA5ikjdNr",
        "flYmGfyAUq0v",
        "O13S15wfpFVQ",
        "A11Xzea-rXdt",
        "-XSlh-yBJ4-j"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_gFMMEA0k1OY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data and Model Preparation"
      ]
    },
    {
      "metadata": {
        "id": "4nmlIW0FX7Wc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "UAxVzZ_UX9Nd",
        "colab_type": "code",
        "outputId": "dd0b982d-b731-46b7-cc85-b4caa3c19f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "\n",
        "SPLIT_TYPE = 'rand' # @param ['rand', 'qtoken']\n",
        "DATA_URL = r'https://s3.amazonaws.com/commensenseqa/'\n",
        "DATA_TRAIN_URL = DATA_URL+'train_'+SPLIT_TYPE+'_split.jsonl'\n",
        "DATA_VALID_URL = DATA_URL+'dev_'+SPLIT_TYPE+'_split.jsonl'\n",
        "DATA_TEST_URL = DATA_URL+'test_'+SPLIT_TYPE+'_split_no_answers.jsonl'\n",
        "\n",
        "!wget $DATA_TRAIN_URL -O data/train.jsonl\n",
        "!wget $DATA_VALID_URL -O data/dev.jsonl\n",
        "!wget $DATA_TEST_URL -O data/test.jsonl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-17 15:29:25--  https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.86.69\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.86.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3513912 (3.4M) [binary/octet-stream]\n",
            "Saving to: ‘data/train.jsonl’\n",
            "\n",
            "data/train.jsonl    100%[===================>]   3.35M  15.2MB/s    in 0.2s    \n",
            "\n",
            "2019-03-17 15:29:26 (15.2 MB/s) - ‘data/train.jsonl’ saved [3513912/3513912]\n",
            "\n",
            "--2019-03-17 15:29:26--  https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.86.69\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.86.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 438003 (428K) [binary/octet-stream]\n",
            "Saving to: ‘data/dev.jsonl’\n",
            "\n",
            "data/dev.jsonl      100%[===================>] 427.74K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-17 15:29:27 (3.63 MB/s) - ‘data/dev.jsonl’ saved [438003/438003]\n",
            "\n",
            "--2019-03-17 15:29:29--  https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.109.77\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.109.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 390221 (381K) [binary/octet-stream]\n",
            "Saving to: ‘data/test.jsonl’\n",
            "\n",
            "data/test.jsonl     100%[===================>] 381.08K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-17 15:29:29 (3.16 MB/s) - ‘data/test.jsonl’ saved [390221/390221]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NZg5oAvapesg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare BERT"
      ]
    },
    {
      "metadata": {
        "id": "VJYCdWIWpg6N",
        "colab_type": "code",
        "outputId": "291b95de-0bbe-46d6-d839-db573bfdc981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_model || git clone https://github.com/google-research/bert bert_model\n",
        "\n",
        "if not 'bert_model' in sys.path:\n",
        "  sys.path += ['bert_model']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_model'...\n",
            "remote: Enumerating objects: 317, done.\u001b[K\n",
            "remote: Total 317 (delta 0), reused 0 (delta 0), pack-reused 317\u001b[K\n",
            "Receiving objects: 100% (317/317), 254.91 KiB | 3.44 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpllytgUx4o1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Embedding"
      ]
    },
    {
      "metadata": {
        "id": "-0n56OJRx3-1",
        "colab_type": "code",
        "outputId": "83f7306f-b448-490a-f5e7-0f92a64655ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir embed\n",
        "\n",
        "GLOVE_URL = r'https://s3.eu-west-2.amazonaws.com/csqa-embed/glove_sm.txt'\n",
        "\n",
        "!wget $GLOVE_URL -O embed/glove_sm.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-17 15:29:34--  https://s3.eu-west-2.amazonaws.com/csqa-embed/glove_sm.txt\n",
            "Resolving s3.eu-west-2.amazonaws.com (s3.eu-west-2.amazonaws.com)... 52.95.150.64\n",
            "Connecting to s3.eu-west-2.amazonaws.com (s3.eu-west-2.amazonaws.com)|52.95.150.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44697629 (43M) [text/plain]\n",
            "Saving to: ‘embed/glove_sm.txt’\n",
            "\n",
            "embed/glove_sm.txt  100%[===================>]  42.63M  20.3MB/s    in 2.1s    \n",
            "\n",
            "2019-03-17 15:29:37 (20.3 MB/s) - ‘embed/glove_sm.txt’ saved [44697629/44697629]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XtatYb9aYBR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ]
    },
    {
      "metadata": {
        "id": "_RrDP1HEhOOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "HlXoDxB0XsEf",
        "colab_type": "code",
        "outputId": "cd8788ce-1c6b-496d-f831-1d54f19fa5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorboardcolab as tbc\n",
        "\n",
        "from keras import utils\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "from keras import callbacks as cbs\n",
        "from keras import optimizers as opt\n",
        "from keras import initializers as ini\n",
        "from keras import preprocessing as pre\n",
        "\n",
        "import tokenization as tkz\n",
        "import run_classifier as rcf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0317 15:29:38.392063 139920176412544 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BZW8jkTAlfW0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ]
    },
    {
      "metadata": {
        "id": "umAq5aHuYwKw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Example Structure"
      ]
    },
    {
      "metadata": {
        "id": "TQYXpWG0Yxl0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CsQAExample(object):\n",
        "  \n",
        "  def __init__(self, uid, Q, A, label):\n",
        "    self.uid = uid\n",
        "    self.Q = Q\n",
        "    self.A = A\n",
        "    self.label = label\n",
        "    assert isinstance(A, (list, tuple)), 'A must be an instance of list or tuple'\n",
        "    assert len(A) == 5, 'length of A should be 3, but got {}'.format(len(A))\n",
        "    \n",
        "  def __str__(self):\n",
        "    return self.__repr__()\n",
        "  \n",
        "  def __repr__(self):\n",
        "    l = [\n",
        "        'uid: {}'.format(self.uid),\n",
        "        'Q: {}'.format(self.Q),\n",
        "        'A0: {}'.format(self.A[0]),\n",
        "        'A1: {}'.format(self.A[1]),\n",
        "        'A2: {}'.format(self.A[2]),\n",
        "        'A3: {}'.format(self.A[3]),\n",
        "        'A4: {}'.format(self.A[4]),\n",
        "        'label: {}'.format(self.label)\n",
        "    ]\n",
        "    return '; '.join(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tc4Zvt0sYyNu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Processor"
      ]
    },
    {
      "metadata": {
        "id": "VgZvKIrkY0lP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CsQAProcessor(object):\n",
        "  \n",
        "  def get_train_examples(self, data_dir):\n",
        "    return self._create_examples(self._read_lines(os.path.join(data_dir, 'train.jsonl')))\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    return self._create_examples(self._read_lines(os.path.join(data_dir, 'dev.jsonl')))\n",
        "\n",
        "  def get_test_examples(self, data_dir):\n",
        "    return self._create_examples(self._read_lines(os.path.join(data_dir, 'test.jsonl')))\n",
        "\n",
        "  def get_labels(self):\n",
        "    return [0, 1, 2, 3, 4]\n",
        "    \n",
        "  def _read_lines(self, path):\n",
        "    return open(path).read().split('\\n')[:-1]\n",
        "    \n",
        "  def _create_examples(self, lines):\n",
        "    ans_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
        "    examples = []\n",
        "    for line in lines:\n",
        "      d = json.loads(line)\n",
        "      uid = d['id']\n",
        "      Q = d['question']['stem']\n",
        "      A = [\n",
        "          d['question']['choices'][0]['text'],\n",
        "          d['question']['choices'][1]['text'],\n",
        "          d['question']['choices'][2]['text'],\n",
        "          d['question']['choices'][3]['text'],\n",
        "          d['question']['choices'][4]['text']\n",
        "      ]\n",
        "      label = ans_dict.get(d.get('answerKey'), -1)\n",
        "      examples.append(CsQAExample(uid, Q, A, label))\n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oR6OwjPa2cgx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "cGvOJaaWy91A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer(object):\n",
        "  \n",
        "  def __init__(self, data_dir, include_set=['train', 'dev', 'test'], do_lower_case=True):\n",
        "    processor = CsQAProcessor()\n",
        "    data = []\n",
        "    if 'train' in include_set:\n",
        "      data.extend(processor.get_train_examples(data_dir))\n",
        "    if 'dev' in include_set:\n",
        "      data.extend(processor.get_dev_examples(data_dir))\n",
        "    if 'test' in include_set:\n",
        "      data.extend(processor.get_test_examples(data_dir))\n",
        "    tokens = set()\n",
        "    self.bstk = tkz.BasicTokenizer(do_lower_case)\n",
        "    for example in data:\n",
        "      Q = example.Q\n",
        "      tokens.update(self.bstk.tokenize(Q))\n",
        "      for A in example.A:\n",
        "        tokens.update(self.bstk.tokenize(A))\n",
        "    self.vocab = collections.OrderedDict()\n",
        "    self.vocab['[PAD]'] = 0\n",
        "    self.vocab['[UNK]'] = 1\n",
        "    self.vocab['[CLS]'] = 2\n",
        "    self.vocab['[SEP]'] = 3\n",
        "    index = 4\n",
        "    for token in sorted(list(tokens)):\n",
        "      self.vocab[token] = index\n",
        "    self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "  \n",
        "  def tokenize(self, text):\n",
        "    return self.bstk.tokenize(text)\n",
        "  \n",
        "  def convert_tokens_to_ids(self, tokens):\n",
        "    return tkz.convert_by_vocab(self.vocab, tokens)\n",
        "  \n",
        "  def convert_ids_to_tokens(self, ids):\n",
        "    return tkz.convert_by_vocab(self.inv_vocab, ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKSx5GC1kzT0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Custom Layers"
      ]
    },
    {
      "metadata": {
        "id": "3Ilhn0hLi-rf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### SEmb Layer"
      ]
    },
    {
      "metadata": {
        "id": "6xbjxwKEjQ3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SEmbLayer(layers.Layer):\n",
        "  \n",
        "  def __init__(self, data_dir, embed_path, trainable=True, **kwargs):\n",
        "    self.output_dim = 300\n",
        "    self.data_dir = data_dir\n",
        "    self.embed_path = embed_path\n",
        "    self.trainable = trainable\n",
        "    super(SEmbLayer, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    tokenizer = SimpleTokenizer(self.data_dir)\n",
        "    embed_df = pd.read_table(self.embed_path, sep=' ', header=None, index_col=0, quoting=csv.QUOTE_NONE)\n",
        "    word_embed = embed_df.loc[tokenizer.vocab.keys(), :].values\n",
        "    nan_mask = np.isnan(word_embed)\n",
        "    word_embed[nan_mask] = np.random.normal(scale=0.02, size=np.count_nonzero(nan_mask))\n",
        "    word_embed[tokenizer.convert_tokens_to_ids(['[PAD]'])] = 0.\n",
        "    word_embed = utils.normalize(word_embed)\n",
        "    voc_size, emb_dim = word_embed.shape\n",
        "    assert emb_dim == self.output_dim\n",
        "    self.embed = self.add_weight(\n",
        "        name='embeddings',\n",
        "        shape=(voc_size, emb_dim),\n",
        "        initializer=ini.Constant(word_embed),\n",
        "        trainable=self.trainable\n",
        "    )\n",
        "    super(SEmbLayer, self).build(input_shape)\n",
        "  \n",
        "  def call(self, x):\n",
        "    _, seq = K.int_shape(x)\n",
        "    mask = K.tf.count_nonzero(x, axis=-1, keepdims=True, dtype=K.tf.float32)\n",
        "    flat_x = K.reshape(x, (-1,))\n",
        "    flat_x_emb = K.gather(self.embed, flat_x)\n",
        "    x_seq = K.reshape(flat_x_emb, (-1, seq, self.output_dim))\n",
        "    feature = K.sum(x_seq, axis=1) / mask\n",
        "    return feature\n",
        "  \n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape[0], self.output_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-770Ck8KY_kC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ELMo Layer"
      ]
    },
    {
      "metadata": {
        "id": "UoivuNbjZFYK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ELMoLayer(layers.Layer):\n",
        "  \n",
        "  def __init__(self, trainable=True, **kwargs):\n",
        "    self.output_dim = 1024\n",
        "    self.trainable = trainable\n",
        "    super(ELMoLayer, self).__init__(**kwargs)\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.elmo = hub.Module(\n",
        "        spec='https://tfhub.dev/google/elmo/2',\n",
        "        trainable=self.trainable,\n",
        "        name='elmo_module'\n",
        "    )\n",
        "    self.trainable_weights += K.tf.trainable_variables(scope='elmo_module/.*')\n",
        "    super(ELMoLayer, self).build(input_shape)\n",
        "  \n",
        "  def call(self, x):\n",
        "    return self.elmo(\n",
        "        inputs=K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "        signature='default',\n",
        "        as_dict=True\n",
        "    )['default']\n",
        "  \n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape[0], self.output_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HengkzJGFmFf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### BERT Layer"
      ]
    },
    {
      "metadata": {
        "id": "7sMMifONFow1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BERTLayer(layers.Layer):\n",
        "  \n",
        "  def __init__(self, trainable=True, **kwargs):\n",
        "    self.output_dim = 768\n",
        "    self.trainable = trainable\n",
        "    super(BERTLayer, self).__init__(**kwargs)\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.bert = hub.Module(\n",
        "        spec='https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1',\n",
        "        trainable=self.trainable,\n",
        "        name='bert_module'\n",
        "    )\n",
        "    self.trainable_weights += K.tf.trainable_variables(scope='bert_module/bert/.*')\n",
        "    self.non_trainable_weights += K.tf.trainable_variables(scope='bert_module/cls/.*')\n",
        "    super(BERTLayer, self).build(input_shape)\n",
        "    \n",
        "  def call(self, x):\n",
        "    input_ids, input_mask, segment_ids = K.tf.unstack(K.tf.transpose(x, perm=[1, 0, 2]))\n",
        "    bert_inputs = dict(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids\n",
        "    )\n",
        "    return self.bert(\n",
        "        inputs=bert_inputs,\n",
        "        signature='tokens',\n",
        "        as_dict=True\n",
        "    )['pooled_output']\n",
        "  \n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape[0], self.output_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "khyd4eGclF8e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "IN22E6xo10eR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### SEmb Feature Extraction Function\n",
        "\n",
        "( FLAG: Flag ) -> lambda"
      ]
    },
    {
      "metadata": {
        "id": "hTd2-8EO15Es",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_semb_feature(FLAG):\n",
        "  semb = SEmbLayer(data_dir=FLAG.data_dir, embed_path=FLAG.embed_path, name='semb_layer')\n",
        "  return lambda x: semb(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HP1fl7KjXNsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ELMo Feature Extraction Function\n",
        "\n",
        "( drop_rate: float ) -> lambda"
      ]
    },
    {
      "metadata": {
        "id": "lOZWo8oeXPS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_elmo_feature():\n",
        "  elmo = ELMoLayer(name='elmo_layer')\n",
        "  out = layers.Dense(256, activation='tanh', name='elmo_dense') # 256\n",
        "  return lambda x: out(elmo(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHy3N4b3ZRo0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### BERT Feature Extraction Function\n",
        "\n",
        "( ) -> lambda"
      ]
    },
    {
      "metadata": {
        "id": "2glHy0keZV8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bert_feature():\n",
        "  bert = BERTLayer(name='bert_layer')\n",
        "  return lambda x: bert(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xe1inMNVX-Uu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Output Function\n",
        "\n",
        "( drop_rate: float, name: str ) -> lambda"
      ]
    },
    {
      "metadata": {
        "id": "AZxM0NljYArl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_output_layer(drop_rate=0.1, name=None):\n",
        "  drop = layers.Dropout(drop_rate, name='{}_output_dropout'.format(name))\n",
        "  out = layers.Dense(1, name='{}_output_dense'.format(name))\n",
        "  return lambda x: out(drop(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vld1M6mqfifY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Models\n",
        "\n",
        "( FLAG: Flag ) -> tuple"
      ]
    },
    {
      "metadata": {
        "id": "M3dZ-YE3l3q1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(FLAG):\n",
        "  \n",
        "  # semb input interface\n",
        "  semb_inputs = [layers.Input(\n",
        "      shape=(4*FLAG.max_seq_length,),\n",
        "      dtype='int32',\n",
        "      name='semb_input_{}'.format(n)\n",
        "  ) for n in range(FLAG.n_choices)]\n",
        "  # elmo input interface\n",
        "  elmo_inputs = [layers.Input(\n",
        "      shape=(1,),\n",
        "      dtype='string',\n",
        "      name='elmo_input_{}'.format(n)\n",
        "  ) for n in range(FLAG.n_choices)]\n",
        "  # bert input interface\n",
        "  bert_inputs = [layers.Input(\n",
        "      shape=(3, FLAG.max_seq_length),\n",
        "      dtype='int32',\n",
        "      name='bert_input_{}'.format(n)\n",
        "  ) for n in range(FLAG.n_choices)]\n",
        "  \n",
        "  # feature extraction layers\n",
        "  semb = get_semb_feature(FLAG) # [B, 300]\n",
        "  elmo = get_elmo_feature() # [B, 256]\n",
        "  bert = get_bert_feature() # [B, 768]\n",
        "  \n",
        "  # semb model\n",
        "  semb_out = get_output_layer(drop_rate=FLAG.semb_output_dropout, name='semb')\n",
        "  semb_vec = [semb_out(semb(x)) for x in semb_inputs]\n",
        "  semb_res = layers.Concatenate(name='semb_choice_concat')(semb_vec)\n",
        "  semb_pred = layers.Softmax(name='semb_pred')(semb_res)\n",
        "  semb_model = models.Model(inputs=semb_inputs, outputs=semb_pred, name='semb_model')\n",
        "  \n",
        "  # elmo model\n",
        "  elmo_out = get_output_layer(drop_rate=FLAG.elmo_output_dropout, name='elmo')\n",
        "  elmo_vec = [elmo_out(elmo(x)) for x in elmo_inputs]\n",
        "  elmo_res = layers.Concatenate(name='elmo_choice_concat')(elmo_vec)\n",
        "  elmo_pred = layers.Softmax(name='elmo_pred')(elmo_res)\n",
        "  elmo_model = models.Model(inputs=elmo_inputs, outputs=elmo_pred, name='elmo_model')\n",
        "  \n",
        "  # bert model\n",
        "  bert_out = get_output_layer(drop_rate=FLAG.bert_output_dropout, name='bert')\n",
        "  bert_vec = [bert_out(bert(x)) for x in bert_inputs]\n",
        "  bert_res = layers.Concatenate(name='bert_choice_concat')(bert_vec)\n",
        "  bert_pred = layers.Softmax(name='bert_pred')(bert_res)\n",
        "  bert_model = models.Model(inputs=bert_inputs, outputs=bert_pred, name='bert_model')\n",
        "  \n",
        "  # hybrid model\n",
        "  comb_out = get_output_layer(drop_rate=FLAG.comb_output_dropout, name='comb')\n",
        "  comb_vec = []\n",
        "  for i in range(FLAG.n_choices):\n",
        "    comb_prt = []\n",
        "    if FLAG.exclude != 'SEmb':\n",
        "      comb_prt.append(semb(semb_inputs[i]))\n",
        "    if FLAG.exclude != 'ELMo':\n",
        "      comb_prt.append(elmo(elmo_inputs[i]))\n",
        "    if FLAG.exclude != 'BERT':\n",
        "      comb_prt.append(bert(bert_inputs[i]))\n",
        "    combined = layers.Concatenate(name='comb_feature_concat_{}'.format(i))(comb_prt) # Concatenate\n",
        "    comb_vec.append(comb_out(combined))\n",
        "  comb_res = layers.Concatenate(name='comb_choice_concat')(comb_vec)\n",
        "  comb_pred = layers.Softmax(name='comb_pred')(comb_res)\n",
        "  comb_model = models.Model(inputs=semb_inputs+elmo_inputs+bert_inputs, outputs=comb_pred, name='comb_model')\n",
        "  \n",
        "  return semb_model, elmo_model, bert_model, comb_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDJRA5ikjdNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loader\n",
        "\n",
        "( FLAG: Flag ) -> dict"
      ]
    },
    {
      "metadata": {
        "id": "fuKBxF00jfGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(FLAG):\n",
        "  # load BERT tokenization info\n",
        "  bert_module = hub.Module('https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1')\n",
        "  token_info = bert_module(signature='tokenization_info', as_dict=True)\n",
        "  with tf.Session():\n",
        "    vocab_file = token_info['vocab_file'].eval()\n",
        "    do_lower_case = token_info['do_lower_case'].eval()\n",
        "  \n",
        "  ftkz = tkz.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "  stkz = SimpleTokenizer(FLAG.data_dir, do_lower_case=do_lower_case)\n",
        "  \n",
        "  processor = CsQAProcessor()\n",
        "  \n",
        "  # target\n",
        "  # semb (5, N, S), int32\n",
        "  # elmo (5, N, 1), string\n",
        "  # bert (5, N, 3, S), int32\n",
        "  # label (N, 5), float32\n",
        "  \n",
        "  def to_features(examples):\n",
        "    semb_features = [] # (N, 5, S)\n",
        "    elmo_features = [] # (N, 5)\n",
        "    bert_features = [] # (N, 5, 3, S)\n",
        "    labels = [] # (N, 3)\n",
        "    for example in examples:\n",
        "      semb_feature = [] # (5, S)\n",
        "      elmo_feature = [] # (5,)\n",
        "      bert_feature = [] # (5, 3, S)\n",
        "      Q = example.Q\n",
        "      Q_stk = stkz.tokenize(Q)\n",
        "      _Q_ftk = ftkz.tokenize(Q)\n",
        "      for A in example.A:\n",
        "        # semb\n",
        "        A_stk = stkz.tokenize(A)\n",
        "        s_tokens = Q_stk + A_stk\n",
        "        s_tk_ids = stkz.convert_tokens_to_ids(s_tokens)\n",
        "        zero_pad = [0] * (4*FLAG.max_seq_length - len(s_tk_ids))\n",
        "        s_tk_ids += zero_pad\n",
        "        semb_feature.append(s_tk_ids)\n",
        "        # elmo\n",
        "        sentence = ' '.join([Q, A])\n",
        "        elmo_feature.append(sentence)\n",
        "        # bert\n",
        "        Q_tk = _Q_ftk[:]\n",
        "        A_tk = ftkz.tokenize(A)\n",
        "        rcf._truncate_seq_pair(Q_tk, A_tk, FLAG.max_seq_length-3)\n",
        "        tokens = ['[CLS]'] + Q_tk + ['[SEP]'] + A_tk + ['[SEP]']\n",
        "        input_ids = ftkz.convert_tokens_to_ids(tokens)\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        segment_ids = [0] * (len(Q_tk)+2) + [1] * (len(A_tk)+1)\n",
        "        padding = [0] * (FLAG.max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "        assert len(input_ids) == FLAG.max_seq_length, 'Require {0}, actual {1}'.format(FLAG.max_seq_length, len(input_ids))\n",
        "        assert len(input_mask) == FLAG.max_seq_length, 'Require {0}, actual {1}'.format(FLAG.max_seq_length, len(input_mask))\n",
        "        assert len(segment_ids) == FLAG.max_seq_length, 'Require {0}, actual {1}'.format(FLAG.max_seq_length, len(segment_ids))\n",
        "        bert_feature.append([input_ids, input_mask, segment_ids]) # (3, S)\n",
        "      semb_features.append(semb_feature)\n",
        "      elmo_features.append(elmo_feature)\n",
        "      bert_features.append(bert_feature)\n",
        "      labels.append(np.eye(FLAG.n_choices)[example.label])\n",
        "    semb_features = np.transpose(semb_features, (1, 0, 2)).tolist() # (5, N, S)\n",
        "    elmo_features = np.transpose(elmo_features)[:,:,None].tolist() # (5, N, 1)\n",
        "    bert_features = np.transpose(bert_features, (1, 0, 2, 3)).tolist() # (5, N, 3, S)\n",
        "    semb_inputs = []\n",
        "    elmo_inputs = []\n",
        "    bert_inputs = []\n",
        "    for n in range(FLAG.n_choices):\n",
        "      semb_inputs.append(np.asarray(semb_features[n], dtype=np.int32))\n",
        "      elmo_inputs.append(np.asarray(elmo_features[n]))\n",
        "      bert_inputs.append(np.asarray(bert_features[n], dtype=np.int32))\n",
        "    label_inputs = np.asarray(labels, dtype=np.float32)\n",
        "    return semb_inputs, elmo_inputs, bert_inputs, label_inputs\n",
        "  \n",
        "  data = {'train': {}, 'dev': {}, 'test': {}}\n",
        "  data['train']['semb'], data['train']['elmo'], data['train']['bert'], data['train']['label'] = to_features(processor.get_train_examples(FLAG.data_dir))\n",
        "  data['train']['comb'] = data['train']['semb'] + data['train']['elmo'] + data['train']['bert']\n",
        "  data['dev']['semb'], data['dev']['elmo'], data['dev']['bert'], data['dev']['label'] = to_features(processor.get_dev_examples(FLAG.data_dir))\n",
        "  data['dev']['comb'] = data['dev']['semb'] + data['dev']['elmo'] + data['dev']['bert']\n",
        "  data['test']['semb'], data['test']['elmo'], data['test']['bert'], _ = to_features(processor.get_test_examples(FLAG.data_dir))\n",
        "  data['test']['comb'] = data['test']['semb'] + data['test']['elmo'] + data['test']['bert']\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flYmGfyAUq0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation\n",
        "\n",
        "( model: keras.models.Model, data:  dict, FLAG: Flag ) -> None"
      ]
    },
    {
      "metadata": {
        "id": "F2yL-XOhUs5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_eval(model, data, FLAG):\n",
        "  \n",
        "  # obtain model parameters\n",
        "  model_type = model.name.replace('_model', '')\n",
        "  learning_rate = getattr(FLAG, '{}_learning_rate'.format(model_type))\n",
        "  warmup_ratio = getattr(FLAG, '{}_warmup_ratio'.format(model_type))\n",
        "  batch_size = getattr(FLAG, '{}_batch_size'.format(model_type))\n",
        "  granulity = getattr(FLAG, '{}_granulity'.format(model_type))\n",
        "  epochs = getattr(FLAG, '{}_epochs'.format(model_type))\n",
        "  \n",
        "  # number of train samples\n",
        "  n_train = len(data['train']['label'])\n",
        "  # number of dev samples\n",
        "  n_valid = len(data['dev']['label'])\n",
        "  \n",
        "  # number of steps per epoch\n",
        "  epoch_steps = int(n_train/batch_size)\n",
        "  # number of total steps\n",
        "  total_steps = int(epochs*epoch_steps)\n",
        "  \n",
        "  # callbacks\n",
        "  cb = cbs.CallbackList()\n",
        "  cb.append(cbs.ModelCheckpoint(\n",
        "      filepath=os.path.join(FLAG.ckpt_dir, model_type+'.{epoch:02d}-{val_acc:.4f}.h5'),\n",
        "      monitor='val_acc',\n",
        "      save_best_only=True,\n",
        "      save_weights_only=True\n",
        "  ))\n",
        "  cb.append(cbs.TensorBoard(\n",
        "      log_dir=os.path.join(FLAG.log_dir, model_type+'/'),\n",
        "      update_freq=3*batch_size\n",
        "  ))\n",
        "  cb.append(cbs.ProgbarLogger(\n",
        "      count_mode='steps',\n",
        "      stateful_metrics=['val_loss', 'val_acc']\n",
        "  ))\n",
        "  cb.set_params({\n",
        "      'verbose': 1,\n",
        "      'epochs': epochs,\n",
        "      'samples': n_train,\n",
        "      'steps': epoch_steps,\n",
        "      'metrics': ['loss', 'acc', 'val_loss', 'val_acc']\n",
        "  })\n",
        "  cb.set_model(model)\n",
        "  \n",
        "  # output logs\n",
        "  log = {'size': batch_size}\n",
        "  \n",
        "  # learning rate schedule\n",
        "  lrs = lambda s: K.set_value(\n",
        "      x=model.optimizer.lr,\n",
        "      value=(learning_rate-K.epsilon())*(1-s/total_steps)**0.8+K.epsilon()\n",
        "  )\n",
        "  \n",
        "  # evaluate model\n",
        "  val = lambda: model.evaluate(\n",
        "      x=data['dev'][model_type],\n",
        "      y=data['dev']['label'],\n",
        "      batch_size=batch_size,\n",
        "      verbose=0\n",
        "  )\n",
        "  \n",
        "  # warmup steps\n",
        "  warmup_steps = int(warmup_ratio*total_steps)\n",
        "  warmup_round = int(warmup_steps/epoch_steps)\n",
        "  if warmup_steps:\n",
        "    print('Warming up ...')\n",
        "    pg = utils.Progbar(target=warmup_steps, stateful_metrics=['val_loss', 'val_acc'])\n",
        "    for turn in range(warmup_round+1):\n",
        "      slices = np.random.permutation(n_train)\n",
        "      for step in range(warmup_steps-turn*epoch_steps):\n",
        "        K.set_value(model.optimizer.lr, learning_rate*(turn*epoch_steps+step+1)/warmup_steps)\n",
        "        index = slices[step*batch_size:(step+1)*batch_size]\n",
        "        batch = [d[index] for d in data['train'][model_type]]\n",
        "        label = data['train']['label'][index]\n",
        "        res = model.train_on_batch(x=batch, y=label)\n",
        "        pg.update(step, [('loss', res[0]), ('acc', res[1])])\n",
        "      val_loss, val_acc = val()\n",
        "      pg.update(warmup_steps-turn*epoch_steps, [('val_loss', val_loss), ('val_acc', val_acc)])\n",
        "  \n",
        "  # train and evaluation steps\n",
        "  print('Train on {0} samples, validate on {1} samples'.format(n_train, n_valid))\n",
        "  print('Total steps: {0}, {1} steps per epoch'.format(total_steps, epoch_steps))\n",
        "  cb.on_train_begin(logs=log)\n",
        "  steps = 0\n",
        "  for itr in range(epochs):\n",
        "    cb.on_epoch_begin(itr, logs=log)\n",
        "    slices = np.random.permutation(n_train)\n",
        "    for step in range(epoch_steps):\n",
        "      log.update({'batch': step})\n",
        "      cb.on_batch_begin(step, logs=log)\n",
        "      steps += 1\n",
        "      index = slices[step*batch_size:(step+1)*batch_size]\n",
        "      batch = [d[index] for d in data['train'][model_type]]\n",
        "      label = data['train']['label'][index]\n",
        "      res = model.train_on_batch(x=batch, y=label)\n",
        "      log.update({'loss': res[0], 'acc': res[1]})\n",
        "      if steps % granulity == 0:\n",
        "        lrs(steps)\n",
        "        gc.collect()\n",
        "        val_loss, val_acc = val()\n",
        "        log.update({'val_loss': val_loss, 'val_acc': val_acc, 'lr': K.get_value(model.optimizer.lr)})\n",
        "      cb.on_batch_end(step, logs=log)\n",
        "    val_loss, val_acc = val()\n",
        "    log.update({'val_loss': val_loss, 'val_acc': val_acc})\n",
        "    cb.on_epoch_end(itr, logs=log)\n",
        "  cb.on_train_end(logs=log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XIqGqnNjlC6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run Classifier"
      ]
    },
    {
      "metadata": {
        "id": "O13S15wfpFVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Main Procedure\n",
        "\n",
        "( FLAG: Flag ) -> None"
      ]
    },
    {
      "metadata": {
        "id": "sZr4iiU9pHB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main(FLAG):\n",
        "  \n",
        "  tf.logging.set_verbosity(FLAG.logging_level)\n",
        "  tf.gfile.MakeDirs(FLAG.ckpt_dir)\n",
        "  tf.gfile.MakeDirs(FLAG.log_dir)\n",
        "  \n",
        "  print('Loading data...')\n",
        "  data = load_data(FLAG)\n",
        "  gc.collect()\n",
        "  print('Building models...')\n",
        "  semb_model, elmo_model, bert_model, comb_model = build_model(FLAG)\n",
        "  gc.collect()\n",
        "  \n",
        "  if FLAG.semb: # SEmb fine-tuning\n",
        "    print('Running SEmb...')\n",
        "    if FLAG.semb_checkpoint_path:\n",
        "      semb_model.load_weights(FLAG.semb_checkpoint_path)\n",
        "      print('SEmb weights loaded.')\n",
        "    semb_model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=opt.Adam(lr=FLAG.semb_learning_rate),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    semb_model.summary()\n",
        "    train_and_eval(semb_model, data, FLAG)\n",
        "  \n",
        "  if FLAG.elmo: # ELMo fine-tuning\n",
        "    print('Running ELMo...')\n",
        "    if FLAG.elmo_checkpoint_path:\n",
        "      elmo_model.load_weights(FLAG.elmo_checkpoint_path)\n",
        "      print('ELMo weights loaded.')\n",
        "    elmo_model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=opt.Adam(lr=FLAG.elmo_learning_rate),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    elmo_model.summary()\n",
        "    train_and_eval(elmo_model, data, FLAG)\n",
        "  \n",
        "  if FLAG.bert: # BERT fine-tuning\n",
        "    print('Running BERT...')\n",
        "    if FLAG.bert_checkpoint_path:\n",
        "      bert_model.load_weights(FLAG.bert_checkpoint_path)\n",
        "      print('BERT weights loaded.')\n",
        "    bert_model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=opt.Adam(lr=FLAG.bert_learning_rate, clipnorm=1.),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    bert_model.summary()\n",
        "    train_and_eval(bert_model, data, FLAG)\n",
        "  \n",
        "  if FLAG.comb: # Hybrid model fine-tuning\n",
        "    print('Running hybrid model...')\n",
        "    if FLAG.semb_checkpoint_path:\n",
        "      semb_model.load_weights(FLAG.semb_checkpoint_path)\n",
        "      print('SEmb weights loaded.')\n",
        "    if FLAG.elmo_checkpoint_path:\n",
        "      elmo_model.load_weights(FLAG.elmo_checkpoint_path)\n",
        "      print('ELMo weights loaded.')\n",
        "    if FLAG.bert_checkpoint_path:\n",
        "      bert_model.load_weights(FLAG.bert_checkpoint_path)\n",
        "      print('BERT weights loaded.')\n",
        "    if FLAG.comb_checkpoint_path:\n",
        "      print('Hybrid model weights loaded.')\n",
        "      comb_model.load_weights(FLAG.comb_checkpoint_path)\n",
        "    if FLAG.freeze_semb:\n",
        "      for layer in semb_model.layers:\n",
        "        layer.trainable = False\n",
        "    if FLAG.freeze_elmo:\n",
        "      for layer in elmo_model.layers:\n",
        "        layer.trainable = False\n",
        "    if FLAG.freeze_bert:\n",
        "      for layer in bert_model.layers:\n",
        "        layer.trainable = False\n",
        "    comb_model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=opt.Adam(lr=FLAG.comb_learning_rate),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    comb_model.summary()\n",
        "    train_and_eval(comb_model, data, FLAG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A11Xzea-rXdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Flag Class"
      ]
    },
    {
      "metadata": {
        "id": "ICHKQOH5rZva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flag(object):\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.logging_level = None\n",
        "    self.embed_path = None\n",
        "    self.data_dir = None\n",
        "    self.ckpt_dir = None\n",
        "    self.log_dir = None\n",
        "    self.n_choices = 3\n",
        "    self.max_seq_length = 32\n",
        "    self.semb_checkpoint_path = None\n",
        "    self.elmo_checkpoint_path = None\n",
        "    self.bert_checkpoint_path = None\n",
        "    self.comb_checkpoint_path = None\n",
        "    self.semb_output_dropout = 0.1\n",
        "    self.elmo_output_dropout = 0.1\n",
        "    self.bert_output_dropout = 0.1\n",
        "    self.comb_output_dropout = 0.1\n",
        "    self.semb_learning_rate = 1e-3\n",
        "    self.elmo_learning_rate = 1e-3\n",
        "    self.bert_learning_rate = 1e-5\n",
        "    self.comb_learning_rate = 1e-5\n",
        "    self.semb_warmup_ratio = 0.01\n",
        "    self.elmo_warmup_ratio = 0.01\n",
        "    self.bert_warmup_ratio = 0.01\n",
        "    self.comb_warmup_ratio = 0.01\n",
        "    self.semb_batch_size = 32\n",
        "    self.elmo_batch_size = 32\n",
        "    self.bert_batch_size = 32\n",
        "    self.comb_batch_size = 32\n",
        "    self.semb_granulity = 77\n",
        "    self.elmo_granulity = 77\n",
        "    self.bert_granulity = 77\n",
        "    self.comb_granulity = 10\n",
        "    self.semb_epochs = 9\n",
        "    self.elmo_epochs = 9\n",
        "    self.bert_epochs = 3\n",
        "    self.comb_epochs = 3\n",
        "    self.exclude = None\n",
        "    self.freeze_semb = False\n",
        "    self.freeze_elmo = False\n",
        "    self.freeze_bert = False\n",
        "    self.semb = False\n",
        "    self.elmo = False\n",
        "    self.bert = False\n",
        "    self.comb = False\n",
        "    \n",
        "FLAG = Flag()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLxsCd7sJb_U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Parameters"
      ]
    },
    {
      "metadata": {
        "id": "jReXDHSPJcpn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title Model Parameters { run: 'auto' }\n",
        "# @markdown #### General Settings\n",
        "FLAG.logging_level = \"ERROR\" # @param ['DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL']\n",
        "FLAG.embed_path = \"embed/glove_sm.txt\" # @param {type: 'string'}\n",
        "FLAG.data_dir = \"data/\" # @param {type:'string'}\n",
        "FLAG.ckpt_dir = \"ckpt/\" # @param {type:'string'}\n",
        "FLAG.log_dir = \"log/\" # @param {type:'string'}\n",
        "FLAG.n_choices = 5 # @param {type:\"integer\"}\n",
        "FLAG.max_seq_length = 32 # @param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "# @markdown #### SEmb Model Parameters\n",
        "FLAG.semb_checkpoint_path = \"ckpt/semb.01-0.1788.h5\" # @param {type:'string'}\n",
        "FLAG.semb_output_dropout = 0.05 # @param {type:\"number\"}\n",
        "FLAG.semb_learning_rate = 1e-5 # @param {type:\"number\"}\n",
        "FLAG.semb_warmup_ratio = 0.01 # @param {type:\"number\"}\n",
        "FLAG.semb_batch_size = 64 # @param {type:\"integer\"}\n",
        "FLAG.semb_granulity = 77 # @param {type:\"integer\"}\n",
        "FLAG.semb_epochs = 1 # @param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "# @markdown #### ELMo Model Parameters\n",
        "FLAG.elmo_checkpoint_path = \"ckpt/elmo.08-0.3333.h5\" # @param {type:'string'}\n",
        "FLAG.elmo_output_dropout = 0.05 # @param {type:\"number\"}\n",
        "FLAG.elmo_learning_rate = 1e-3 # @param {type:\"number\"}\n",
        "FLAG.elmo_warmup_ratio = 0.01 # @param {type:\"number\"}\n",
        "FLAG.elmo_batch_size = 64 # @param {type:\"integer\"}\n",
        "FLAG.elmo_granulity = 77 # @param {type:\"integer\"}\n",
        "FLAG.elmo_epochs = 7 # @param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "# @markdown #### BERT Model Parameters\n",
        "FLAG.bert_checkpoint_path = \"ckpt/bert.01-0.5340.h5\" # @param {type:'string'}\n",
        "FLAG.bert_output_dropout = 0.05 # @param {type:\"number\"}\n",
        "FLAG.bert_learning_rate = 1e-5 # @param {type:\"number\"}\n",
        "FLAG.bert_warmup_ratio = 0.05 # @param {type:\"number\"}\n",
        "FLAG.bert_batch_size = 32 # @param {type:\"integer\"}\n",
        "FLAG.bert_granulity = 77 # @param {type:\"integer\"}\n",
        "FLAG.bert_epochs = 1 # @param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "# @markdown #### Hybrid Model Parameters\n",
        "FLAG.comb_checkpoint_path = \"\" # @param {type:'string'}\n",
        "FLAG.comb_output_dropout = 0.1 # @param {type:\"number\"}\n",
        "FLAG.comb_learning_rate = 1e-5 # @param {type:\"number\"}\n",
        "FLAG.comb_warmup_ratio = 0.01 # @param {type:\"number\"}\n",
        "FLAG.comb_batch_size = 32 # @param {type:\"integer\"}\n",
        "FLAG.comb_granulity = 20 # @param {type:\"integer\"}\n",
        "FLAG.comb_epochs = 1 # @param {type:\"integer\"}\n",
        "FLAG.exclude = \"None\" # @param ['None', 'SEmb', 'ELMo', 'BERT']\n",
        "FLAG.freeze_semb = False # @param {type:\"boolean\"}\n",
        "FLAG.freeze_elmo = False # @param {type:\"boolean\"}\n",
        "FLAG.freeze_bert = False # @param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ei3JK6OgK2yQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Mode"
      ]
    },
    {
      "metadata": {
        "id": "zCJc9bsqK7ND",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title Model to Run { run: 'auto' }\n",
        "FLAG.semb = False # @param {type:\"boolean\"}\n",
        "FLAG.elmo = False # @param {type:\"boolean\"}\n",
        "FLAG.bert = False # @param {type:\"boolean\"}\n",
        "FLAG.comb = True # @param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1XEHFThXonm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "OgGo5AW8XqwJ",
        "colab_type": "code",
        "outputId": "0cc25ef7-38e5-497b-a52e-098133e0e1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "tbc.TensorBoardColab(graph_path=FLAG.log_dir);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://b90483f7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6JG0UzNvabS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run Classifier"
      ]
    },
    {
      "metadata": {
        "id": "0QVSO1QmvcOH",
        "colab_type": "code",
        "outputId": "44e8b5d4-3e05-476a-993e-ffc1d017b426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3294
        }
      },
      "cell_type": "code",
      "source": [
        "main(FLAG)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Building models...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running hybrid model...\n",
            "SEmb weights loaded.\n",
            "ELMo weights loaded.\n",
            "BERT weights loaded.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "elmo_input_0 (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_input_1 (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_input_2 (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_input_3 (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_input_4 (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_input_0 (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_layer (ELMoLayer)          (None, 1024)         4           elmo_input_0[0][0]               \n",
            "                                                                 elmo_input_1[0][0]               \n",
            "                                                                 elmo_input_2[0][0]               \n",
            "                                                                 elmo_input_3[0][0]               \n",
            "                                                                 elmo_input_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bert_input_0 (InputLayer)       (None, 3, 32)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_input_1 (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_input_1 (InputLayer)       (None, 3, 32)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_input_2 (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_input_2 (InputLayer)       (None, 3, 32)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_input_3 (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_input_3 (InputLayer)       (None, 3, 32)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_input_4 (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_input_4 (InputLayer)       (None, 3, 32)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "semb_layer (SEmbLayer)          (None, 300)          3879000     semb_input_0[0][0]               \n",
            "                                                                 semb_input_1[0][0]               \n",
            "                                                                 semb_input_2[0][0]               \n",
            "                                                                 semb_input_3[0][0]               \n",
            "                                                                 semb_input_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "elmo_dense (Dense)              (None, 256)          262400      elmo_layer[5][0]                 \n",
            "                                                                 elmo_layer[6][0]                 \n",
            "                                                                 elmo_layer[7][0]                 \n",
            "                                                                 elmo_layer[8][0]                 \n",
            "                                                                 elmo_layer[9][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer (BERTLayer)          (None, 768)          110104890   bert_input_0[0][0]               \n",
            "                                                                 bert_input_1[0][0]               \n",
            "                                                                 bert_input_2[0][0]               \n",
            "                                                                 bert_input_3[0][0]               \n",
            "                                                                 bert_input_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "comb_feature_concat_0 (Concaten (None, 1324)         0           semb_layer[5][0]                 \n",
            "                                                                 elmo_dense[5][0]                 \n",
            "                                                                 bert_layer[5][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "comb_feature_concat_1 (Concaten (None, 1324)         0           semb_layer[6][0]                 \n",
            "                                                                 elmo_dense[6][0]                 \n",
            "                                                                 bert_layer[6][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "comb_feature_concat_2 (Concaten (None, 1324)         0           semb_layer[7][0]                 \n",
            "                                                                 elmo_dense[7][0]                 \n",
            "                                                                 bert_layer[7][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "comb_feature_concat_3 (Concaten (None, 1324)         0           semb_layer[8][0]                 \n",
            "                                                                 elmo_dense[8][0]                 \n",
            "                                                                 bert_layer[8][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "comb_feature_concat_4 (Concaten (None, 1324)         0           semb_layer[9][0]                 \n",
            "                                                                 elmo_dense[9][0]                 \n",
            "                                                                 bert_layer[9][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "comb_output_dropout (Dropout)   (None, 1324)         0           comb_feature_concat_0[0][0]      \n",
            "                                                                 comb_feature_concat_1[0][0]      \n",
            "                                                                 comb_feature_concat_2[0][0]      \n",
            "                                                                 comb_feature_concat_3[0][0]      \n",
            "                                                                 comb_feature_concat_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "comb_output_dense (Dense)       (None, 1)            1325        comb_output_dropout[0][0]        \n",
            "                                                                 comb_output_dropout[1][0]        \n",
            "                                                                 comb_output_dropout[2][0]        \n",
            "                                                                 comb_output_dropout[3][0]        \n",
            "                                                                 comb_output_dropout[4][0]        \n",
            "__________________________________________________________________________________________________\n",
            "comb_choice_concat (Concatenate (None, 5)            0           comb_output_dense[0][0]          \n",
            "                                                                 comb_output_dense[1][0]          \n",
            "                                                                 comb_output_dense[2][0]          \n",
            "                                                                 comb_output_dense[3][0]          \n",
            "                                                                 comb_output_dense[4][0]          \n",
            "__________________________________________________________________________________________________\n",
            "comb_pred (Softmax)             (None, 5)            0           comb_choice_concat[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 114,247,619\n",
            "Trainable params: 113,624,969\n",
            "Non-trainable params: 622,650\n",
            "__________________________________________________________________________________________________\n",
            "Warming up ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 202s 67s/step - loss: 1.5785 - acc: 0.2344 - val_loss: 1.4760 - val_acc: 0.4094\n",
            "Train on 9860 samples, validate on 1236 samples\n",
            "Total steps: 308, 308 steps per epoch\n",
            "Epoch 1/1\n",
            " 59/308 [====>.........................] - ETA: 27:33 - loss: 1.1917 - acc: 0.5392 - val_loss: 1.2471 - val_acc: 0.4676"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-59bcf316d24d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-412d242497c4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(FLAG)\u001b[0m\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m     \u001b[0mcomb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtrain_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-41c86e35bb3e>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, data, FLAG)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mlrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-41c86e35bb3e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-XSlh-yBJ4-j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Store Checkpoint"
      ]
    },
    {
      "metadata": {
        "id": "FtyfKpn6J8WE",
        "colab_type": "code",
        "outputId": "9605c7ce-6f89-4714-c11f-d90598d51ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTC8ErlJKivI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r ckpt/ gdrive/My\\ Drive/ckpt_elmo_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6COLDY2DyB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/My\\ Drive/ckpt_3models/ ckpt"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}